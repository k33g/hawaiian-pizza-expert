#!/bin/sh
#set -e
export MODEL_RUNNER_URL=http://model-runner.docker.internal/engines/llama.cpp/v1/
export LLM=ai/llama3.2
npm start
